{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Example #01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using a Ready-Made CNN model (Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if necessary.\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings                   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets.cifar10 import load_data                           \n",
    "from keras.models import Model                       # We will use Functional API.\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications.mobilenet import MobileNet   # We will use a relatively small neural network.\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "warnings.filterwarnings('ignore')                    # Turn the warnings off.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the dataset can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the data.\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "n_train_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the shapes.\n",
    "print(\"-\"*50)\n",
    "print(\"Training data X shape: {}\".format(X_train.shape))\n",
    "print(\"Training data y shape: {}\".format(y_train.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"Test data X shape: {}\".format(X_test.shape))\n",
    "print(\"Test data y shape: {}\".format(y_test.shape))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_image = 123                                   # You may change this at will. \n",
    "plt.imshow(X_train[i_image,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling.\n",
    "X_train = X_train/255                   \n",
    "X_test = X_test/255                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping.\n",
    "X_train = X_train.reshape(-1,32,32,3)\n",
    "X_test = X_test.reshape(-1,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding.\n",
    "y = np.concatenate([y_train,y_test],axis=0)\n",
    "y = to_categorical(y,10)\n",
    "y_train = y[:n_train_size,:]\n",
    "y_test = y[n_train_size:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Download a pre-trained CNN model and prepare it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the convolutional base: include_top = False.\n",
    "# input_shape = (32,32,3) to conform with the image size.\n",
    "my_conv = MobileNet(include_top=False, weights='imagenet',input_shape = (32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print out the pre-trained layers.\n",
    "i = 0\n",
    "for my_layer in my_conv.layers:\n",
    "    print(\"Layer #{} : '{}' is trainable = {}\".format(i,my_layer.__class__.__name__, my_layer.trainable))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the trainable property to False => Freeze the weights of the convolutional base.\n",
    "# This would be necessary if you want to just \"fine-tune\".\n",
    "# If you want to retrain the whole network, leave the following two lines as comments.\n",
    "\n",
    "#for my_layer in my_conv.layers:\n",
    "#    my_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, show a summary.\n",
    "my_conv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Now, attach the classification layers on top of the convolutional base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input and output of the convolutional base.\n",
    "my_input = my_conv.input\n",
    "my_output = Flatten()(my_conv.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the rest of the output layers.\n",
    "drop_prob = 0.5\n",
    "# Attach a fully connected layer.\n",
    "my_output = Dense(units = 512, activation=\"relu\")(my_output)             # 512 comes from running summary() function.\n",
    "# Apply dropout.\n",
    "my_output = Dropout(rate=drop_prob)(my_output)\n",
    "# The output layer.\n",
    "my_output = Dense(units = 10, activation=\"softmax\")(my_output)           # There are 10 labels.\n",
    "# Finally, use the Functional API to build the model.\n",
    "my_model = Model(inputs=my_input,outputs=my_output)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the summary of the entire fine-tuning model.\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Define the hyperparameters and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters.\n",
    "n_epochs = 10\n",
    "batch_size = 10\n",
    "learn_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and then compile.\n",
    "my_optimizer=Adam(lr=learn_rate)\n",
    "my_model.compile(loss = \"categorical_crossentropy\", optimizer = my_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. Train the model and visualize the history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "# verbose = 0 means no output. verbose = 1 to view the epochs.\n",
    "my_summary = my_model.fit(X_train, y_train, epochs=n_epochs, batch_size = batch_size, validation_split = 0.3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training history. \n",
    "n_skip = 0                 # Skip the first few steps.\n",
    "plt.plot(my_summary.history['accuracy'][n_skip:], c=\"b\")\n",
    "plt.plot(my_summary.history['val_accuracy'][n_skip:], c=\"g\")\n",
    "plt.title('Training History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8. Testing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = my_model.evaluate(X_test, y_test, verbose=0)[1]    \n",
    "print(\"Test Accuracy : {}\".format(np.round(ACC,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
